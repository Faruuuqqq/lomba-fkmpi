# E2E Testing for MITRA AI Platform

This directory contains comprehensive end-to-end tests for the MITRA AI platform's analytics and new AI features.

## ğŸš€ Getting Started

### Prerequisites
- Node.js 18+ installed
- Playwright browsers installed (`npm run test:e2e:install`)

### Running Tests

```bash
# Run all E2E tests
npm run test:e2e

# Run tests in headed mode (visible browser)
npm run test:e2e:headed

# Run tests in debug mode
npm run test:e2e:debug

# Run tests with UI
npm run test:e2e:ui

# Generate test code
npm run test:e2e:generate-code

# View test report
npm run test:e2e:report
```

## ğŸ“ Test Structure

```
tests/e2e/
â”œâ”€â”€ fixtures/
â”‚   â”œâ”€â”€ test-creds.ts          # Test credentials and project data
â”‚   â””â”€â”€ page-fixtures.ts      # Custom Playwright fixtures
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ test-helpers.ts       # Helper functions for common actions
â”‚   â””â”€â”€ cleanup.ts           # Test data cleanup utilities
â”œâ”€â”€ reasoning-map.spec.ts     # Tests for reasoning map generation
â”œâ”€â”€ ethics-check.spec.ts       # Tests for ethics checking
â”œâ”€â”€ analytics.spec.ts         # Tests for analytics dashboard
â”œâ”€â”€ complete-workflow.spec.ts # Tests for complete user workflows
â”œâ”€â”€ setup.ts                 # Global test setup
â””â”€â”€ README.md               # This file
```

## ğŸ§ª Test Coverage

### 1. Reasoning Map Generation Tests
- âœ… Successful map generation
- âœ… Error handling for empty content
- âœ… Data persistence
- âœ… Multiple map generations
- âœ… Loading states
- âœ… Network error handling

### 2. Ethics Checking Tests
- âœ… Successful ethics analysis
- âœ… Identification of ethical issues
- âœ… No issues for ethical content
- âœ… Error handling for empty content
- âœ… Loading states
- âœ… Multiple ethics checks
- âœ… Network error handling
- âœ… Detailed issue explanations

### 3. Analytics Dashboard Tests
- âœ… Dashboard display
- âœ… Zero usage for new users
- âœ… Usage tracking for reasoning maps
- âœ… Usage tracking for ethics checks
- âœ… Combined feature usage
- âœ… Feature usage breakdown
- âœ… Performance metrics
- âœ… Empty state handling
- âœ… Real-time updates
- âœ… Navigation
- âœ… Error handling
- âœ… Response time calculations

### 4. Complete Workflow Tests
- âœ… Full user journey (registration â†’ AI features â†’ analytics)
- âœ… Multiple projects with AI features
- âœ… Data persistence across sessions
- âœ… Concurrent request handling
- âœ… Content validation
- âœ… Different content types

## ğŸ¯ Key Test Features

### Smart Test Data Management
- Automatic cleanup of test projects
- Isolated test environments
- Configurable test credentials

### Robust Error Testing
- Network failure simulation
- Empty content validation
- Loading state verification
- Error message display

### Analytics Verification
- Real-time usage tracking
- Performance metric validation
- Data persistence checks
- Multi-user scenarios

### Complete User Workflows
- Registration to project completion
- AI feature integration testing
- Cross-feature data consistency

## ğŸ”§ Configuration

### Environment Variables
```bash
FRONTEND_URL=http://localhost:3000    # Frontend application URL
DATABASE_URL=postgresql://...        # Test database URL
```

### Playwright Configuration
- Multi-browser support (Chrome, Firefox, Safari)
- Automatic server startup
- Screenshot/video on failure
- Trace files for debugging

## ğŸ“Š Test Data

### Test Projects
- **Sample**: Educational essay about AI in education (150+ words)
- **Minimal**: Short content for validation testing
- **Various**: Scientific, philosophical, and controversial content

### Test Users
- Unique email addresses for test isolation
- Standardized test passwords
- Configurable user names

## ğŸ› ï¸ Test Utilities

### TestHelpers Class
Common actions including:
- User registration/login
- Project creation
- AI feature usage
- Analytics navigation
- Data cleanup

### Custom Fixtures
- `testHelpers`: Pre-configured helper instance
- `authenticatedPage`: Page with logged-in user

## ğŸ“ Best Practices

### Test Isolation
- Each test runs with clean state
- Unique test data for each test
- Automatic cleanup after tests

### Error Scenarios
- Network failures
- Invalid inputs
- Edge cases
- Loading states

### Performance Considerations
- Reasonable timeouts
- Parallel test execution
- Efficient selectors

## ğŸš¨ Important Notes

### Before Running Tests
1. Ensure backend server is running
2. Install Playwright browsers
3. Configure test database
4. Check environment variables

### Test Dependencies
- Backend API must be accessible
- Database must allow test connections
- Frontend must compile successfully

## ğŸ” Debugging

### When Tests Fail
1. Run with `--headed` flag to see browser
2. Use `--debug` mode for step-by-step execution
3. Check test reports and screenshots
4. Review trace files for detailed execution

### Common Issues
- **Timeout failures**: Increase timeout or check loading states
- **Element not found**: Verify selectors and component rendering
- **Network errors**: Check API endpoints and connectivity
- **Data persistence**: Verify database cleanup between tests

## ğŸ“ˆ Coverage Metrics

The E2E test suite covers:
- âœ… All new AI features (reasoning maps, ethics checking)
- âœ… Analytics dashboard functionality
- âœ… Complete user workflows
- âœ… Error handling and edge cases
- âœ… Cross-browser compatibility
- âœ… Performance and reliability

## ğŸš€ Continuous Integration

These tests are designed to run in CI/CD environments:
- Headless execution
- Parallel test running
- Automatic reporting
- Test result artifacts

## ğŸ“š Resources

- [Playwright Documentation](https://playwright.dev/)
- [Test Best Practices](https://playwright.dev/docs/best-practices)
- [Debugging Tests](https://playwright.dev/docs/debug)
- [Test Organization](https://playwright.dev/docs/test-organization)